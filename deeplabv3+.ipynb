{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet101,ResNet101_Weights\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os \n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.functional import F\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir=r\"data/VOCdevkit/VOC2012\", image_size=(512,512), is_train=True, transform=None):\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.image_size = image_size\n",
    "        self.images_list, self.mask_list = self.read_data_list_from(data_dir, self.is_train)\n",
    "        \n",
    "        # 定义默认的Albumentations增强\n",
    "        if self.transform is None:\n",
    "            if self.is_train:\n",
    "                self.aug = A.Compose([\n",
    "                    A.Resize(512, 512),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]),\n",
    "                    ToTensorV2()\n",
    "                ], additional_targets={'mask': 'mask'})\n",
    "            else:\n",
    "                self.aug = A.Compose([\n",
    "                    A.Resize(image_size[0], image_size[1]),\n",
    "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]),\n",
    "                    ToTensorV2()\n",
    "                ], additional_targets={'mask': 'mask'})\n",
    "        else:\n",
    "            self.aug = self.transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images_list[index]\n",
    "        mask_path = self.mask_list[index]\n",
    "        \n",
    "        # 读取图像和mask，转换mask中的255为-1\n",
    "        image = np.array(Image.open(image_path).convert(\"RGB\")).astype(np.float32)\n",
    "        mask = np.array(Image.open(mask_path)).astype(np.int64)\n",
    "        mask[mask==255]=-1  # 提前转换255为-1\n",
    "        \n",
    "        # 应用数据增强\n",
    "        augmented = self.aug(image=image, mask=mask)\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def read_data_list_from(self, root, is_train):\n",
    "        if is_train ==True:\n",
    "            data_dir=os.path.join(root,\"ImageSets\",\"Segmentation\",\"train.txt\")\n",
    "        else:\n",
    "            data_dir=os.path.join(root,\"ImageSets\",\"Segmentation\",\"val.txt\")\n",
    "        fh=open(data_dir)\n",
    "        images=[]\n",
    "        masks=[]\n",
    "        for line in fh:\n",
    "            line=line.strip(\"\\n\")\n",
    "            images.append(os.path.join(root,\"JPEGImages\",line+\".jpg\"))\n",
    "            masks.append(os.path.join(root,\"SegmentationClass\",line+\".png\"))\n",
    "                         \n",
    "        return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=DataLoader(MyDataset(),batch_size=15,num_workers=0,shuffle=True)\n",
    "val_ds=DataLoader(MyDataset(is_train=False),batch_size=15,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,padding):\n",
    "        super().__init__()\n",
    "        self.block=nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size,stride=stride,padding=padding,padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ASPP\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,padding=0)\n",
    "        self.atrous6=nn.Conv2d(in_channels,out_channels,dilation=6,kernel_size=3,stride=1,padding=6,padding_mode=\"reflect\")\n",
    "        self.atrous12=nn.Conv2d(in_channels,out_channels,dilation=12,kernel_size=3,stride=1,padding=12,padding_mode=\"reflect\")\n",
    "        self.atrous18=nn.Conv2d(in_channels,out_channels,dilation=18,kernel_size=3,stride=1,padding=18,padding_mode=\"reflect\")\n",
    "        self.pool=nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,padding=0),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        conv=self.conv(x)\n",
    "        atrous6=self.atrous6(x)\n",
    "        atrous12=self.atrous12(x)\n",
    "        atrous18=self.atrous18(x)\n",
    "        pooled=self.pool(x)\n",
    "        pooled=F.interpolate(\n",
    "            pooled,\n",
    "            size=x.shape[2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=True\n",
    "        )\n",
    "        return torch.cat((conv,atrous6,atrous12,atrous18,pooled),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DeepLabV3+\n",
    "class DeepLabV3P(nn.Module):\n",
    "    def __init__(self,C=21):\n",
    "        super().__init__()\n",
    "        backbone=resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "        for name,param in backbone.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        self.set_dilation(backbone)\n",
    "        self.lower_f=nn.Sequential(*list(backbone.children())[:5])## 256 56 56\n",
    "        self.up_f0=nn.Sequential(*list(backbone.children())[5:7])\n",
    "        self.up_f1=nn.Sequential(*list(backbone.children())[7])## 2048 14 14\n",
    "\n",
    "        self.aspp=ASPP(2048,256)\n",
    "        self.up_conv=ConvBlock(256*5,256,kernel_size=1,stride=1,padding=0)\n",
    "        self.down_conv=ConvBlock(256,128,kernel_size=1,stride=1,padding=0)\n",
    "        self.cat_conv=ConvBlock(256+128,C,kernel_size=3,stride=1,padding=1)\n",
    "    def set_dilation(self,layer,d=2):\n",
    "        p=d\n",
    "        s=1\n",
    "        for n,m in layer.named_modules():\n",
    "            if n in [\"layer3.1.conv2\",\"layer3.2.conv2\",\"layer3.3.conv2\",\"layer3.4.conv2\",\"layer3.5.conv2\",\n",
    "                     \"layer3.6.conv2\",\"layer3.7.conv2\",\"layer3.8.conv2\",\"layer3.9.conv2\",\"layer3.10.conv2\",\n",
    "                     \"layer3.11.conv2\",\"layer3.12.conv2\",\"layer3.13.conv2\",\"layer3.14.conv2\",\"layer3.15.conv2\",\n",
    "                     \"layer3.16.conv2\",\"layer3.17.conv2\",\"layer3.18.conv2\",\"layer3.19.conv2\",\"layer3.20.conv2\",\n",
    "                     \"layer3.21.conv2\",\"layer3.22.conv2\",\"layer.4.0.conv2\"]:\n",
    "                m.dilation=(d,d)\n",
    "                m.padding=(p,p)\n",
    "            elif n in [\"layer3.0.conv2\"]:\n",
    "                m.stride=(s,s)\n",
    "            elif n in [\"layer3.0.downsample.0\"]:\n",
    "                m.stride=(s,s)\n",
    "            elif n in [\"layer4.1.conv2\",\"layer4.2.conv2\"]:\n",
    "                m.dilation=(2*d,2*d)\n",
    "                m.padding=(2*p,2*p)\n",
    "    def forward(self,x):\n",
    "        lower_f=self.lower_f(x)\n",
    "        up_f=self.up_f0(lower_f)\n",
    "        up=self.up_f1(up_f)\n",
    "        aspp=self.aspp(up)\n",
    "        up_out=self.up_conv(aspp)\n",
    "        up_out=F.interpolate(\n",
    "            up_out,\n",
    "            scale_factor=4,\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=True\n",
    "        )\n",
    "\n",
    "        down_out=self.down_conv(lower_f)\n",
    "        cat=torch.cat((up_out,down_out),dim=1)\n",
    "        out=self.cat_conv(cat)\n",
    "        return F.interpolate(out,scale_factor=4,mode=\"bilinear\",align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplab=DeepLabV3P()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 损失函数\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self,alpha=0.25,gamma=2,ignore_dix=255, *args, **kwargs,):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha=alpha\n",
    "        self.gamma=gamma\n",
    "        self.ignore_dix=ignore_dix\n",
    "    def forward(self,inputs,targets):\n",
    "        predict=inputs.permute(0,2,3,1).contiguous()\n",
    "        predict=torch.softmax(predict,dim=-1)\n",
    "        b,c=predict.size(0),predict.size(3)\n",
    "        mask=targets!=self.ignore_dix#(batch_size,h,w)\n",
    "        predict=predict[mask].view(-1,c)\n",
    "        targets=targets[mask].view(-1)\n",
    "        one_hot=torch.eye(c,device=predict.device)\n",
    "        targets=one_hot[targets].view(-1,c).float()#(predict_size,c)\n",
    "        FL=((-self.alpha*((1-predict)**self.gamma))*targets*torch.log2(predict+1e-12)).sum(dim=-1)#(predict_size,)\n",
    "        return FL.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义累加器\n",
    "class Accumulator():\n",
    "    def __init__(self,n):\n",
    "        self.data=[0.0]*n\n",
    "    def add(self,*args):\n",
    "        self.data=[a+float(b) for a,b in zip(self.data,args)]\n",
    "    def reset(self):\n",
    "        self.data=[0.0]*len(self.data)\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义训练函数\n",
    "def train(net,train_iter,val_iter,lr,num_epochs,device=None,patience=20):\n",
    "    # def init_weights(m):\n",
    "    #     if isinstance(m,nn.Conv2d):\n",
    "    #         nn.init.normal_(m.weight.data,0,0.02)\n",
    "    #         if m.bias is not None:\n",
    "    #             nn.init.constant_(m.bias.data,0)\n",
    "    #     elif isinstance(m,nn.BatchNorm2d):\n",
    "    #         nn.init.normal_(m.weight.data,0,0.02)\n",
    "    #         nn.init.constant_(m.bias.data,0)\n",
    "    # net.apply(init_weights)\n",
    "    history=[]\n",
    "    best_val_loss=5.67e-1\n",
    "    counter=0\n",
    "    net.to(device)\n",
    "    print('training on',device)\n",
    "    loss=FocalLoss(ignore_dix=-1)\n",
    "    optimizer=torch.optim.Adam(net.parameters(),lr=lr,weight_decay=5e-4,betas=(0.9,0.99))\n",
    "    batch_size=len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        metric=Accumulator(2)\n",
    "        print(f\"epoch{epoch+1}\")\n",
    "        for i,(X,y) in enumerate(train_iter):\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y=y.squeeze(1).long()\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l,l.numel())\n",
    "            if (i+1)%(batch_size//5)==0 or i==batch_size-1:\n",
    "                print(f'\\tloss {metric[0]/metric[1]:.5e}')\n",
    "        ## 验证模式\n",
    "        net.eval()\n",
    "        metric2=Accumulator(2)\n",
    "        with torch.no_grad():\n",
    "            for X,y in val_iter:\n",
    "                X,y=X.to(device),y.to(device)\n",
    "                y=y.squeeze(1).long()\n",
    "                y_hat=net(X)\n",
    "                l2=loss(y_hat,y)\n",
    "                metric2.add(l2,l2.numel())\n",
    "        print(f'epoch {epoch+1} summary: loss {metric[0]/metric[1]:.5e}, val_loss {metric2[0]/metric2[1]:.5e}')\n",
    "        if metric2[0]/metric2[1]<best_val_loss:\n",
    "            best_val_loss=metric2[0]/metric2[1]\n",
    "            torch.save(net.state_dict(),'model_best_deeplab_2.pth')\n",
    "        else:\n",
    "            counter+=1\n",
    "            if counter>=patience:\n",
    "                print('early stops')\n",
    "                break\n",
    "        print(f\"best val_loss {best_val_loss:.5e}\")\n",
    "        history.append(metric[0]/metric[1])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "epoch1\n"
     ]
    }
   ],
   "source": [
    "## 开始训练！\n",
    "# deeplab.load_state_dict(torch.load(\"model_best_deeplab.pth\",weights_only=False))\n",
    "# for name, param in deeplab.named_parameters():\n",
    "#     if \"lower_f\" in name or \"up_f0\" in name or \"up_f1\" in name:\n",
    "#         param.requires_grad = True\n",
    "history=train(deeplab,train_ds,val_ds,lr=1e-5,num_epochs=40,device=try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
